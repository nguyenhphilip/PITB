# load libraries
sapply(c("tidyverse", "purrr", "here","knitr", "kableExtra","ggpubr","cowplot","gridExtra"), require, character.only = TRUE)
library(cowplot)
install.packages("cowplot")
<div class = "poem">
* While the world sleeps
* I wake
* into the soft unfolding
* of morning.
* &nbsp;
* Between stanzas I’ve suddenly
* forgotten (forgive me Szymborska)
* is clasped
* a single thread
* &nbsp;
* of auburn.
* It’s been months since
* I last found you
* rising
* &nbsp;
* and falling
* like a fawn yet nuzzled
* by the cold breath
* of winter
* &nbsp;
* and demands
* beside me
* beneath familiar sheets.
* My poems miss
* &nbsp;
* your eyes,
* my fingers
* your scars,
* my world
* &nbsp;
* your gravity.
* The strand still lingers
* and dresses herself daily
* in the same sunlight
* &nbsp;
* and the same unturned pages
* I still can't remember,
* still waits for her sisters
* to come again, loosen up
* &nbsp;
* and curl themselves
* around words, lines, and stories
* that have yet to be read
* by more than my eyes
* &nbsp;
* alone.
@@
nsims <- 100000 # number of simulations
m <- 106 # mean sample
m <- 106 # mean sample
n <- 26 # set sample size
sd <- 15 # SD of the simulated data
p <- numeric(nsims) # set up empty vector
bars <- 20
for (i in 1:nsims) { # for each simulated experiment
x <- rnorm(n = n, mean = m, sd = sd)
z <- t.test(x, mu = 100) # perform the t-test
p[i] <- z$p.value # get the p-value
}
power <- round((sum(p < 0.05) / nsims), 2) # power
# Plot figure
hist(p,
breaks = bars, xlab = "P-values", ylab = "number of p-values\n",
axes = FALSE,  main = paste("P-value Distribution with",
round(power * 100, digits = 1), "% Power"),
col = "grey", xlim = c(0, 1), ylim = c(0, nsims))
power
nsims <- 100000 # number of simulations
m <- 106 # mean sample
n <- 51 # set sample size
sd <- 15 # SD of the simulated data
p <- numeric(nsims) # set up empty vector
bars <- 20
for (i in 1:nsims) { # for each simulated experiment
x <- rnorm(n = n, mean = m, sd = sd)
z <- t.test(x, mu = 100) # perform the t-test
p[i] <- z$p.value # get the p-value
}
power <- round((sum(p < 0.05) / nsims), 2) # power
power
library(bayesrules)
install.packages("bayesrules")
install.packages("rstan", dependencies = TRUE)
install.packages("tidyverse")
install.packages("here")
library(lavaan)
d <- HolzingerSwineford1939
library(tidyverse)
d %>% glimpse()
'
fit <- cfa(Hs.model, data = d)
speed =~ x7 + x8 + x9'
# syntax for our latent variable model with three latent factors, each defined by three indicators
Hs.model <-
'visual =~ x1 + x2 + x3
speed =~ x7 + x8 + x9'
# syntax for our latent variable model with three latent factors, each defined by three indicators
Hs.model <- 'visual =~ x1 + x2 + x3
Hs.model <- 'visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9'
speed =~ x7 + x8 + x9'
Hs.model <- '
speed =~ x7 + x8 + x9 '
Hs.model <- ' visual =~ x1 + x2 + x3
Hs.model <- 'visual =~ x1 + x2 + x3 textual =~ x4 + x5 + x6 speed =~ x7 + x8 + x9'
fit <- cfa(Hs.model, data = d)
Hs.model <- 'visual =~ x1 + x2 + x3 textual =~ x4 + x5 + x6 speed =~ x7 + x8 + x9'
fit <- cfa(Hs.model, data = d)
Hs.model <- ' visual =~ x1 + x2 + x3 textual =~ x4 + x5 + x6 speed =~ x7 + x8 + x9 '
fit <- cfa(Hs.model, data = d)
speed =~ x7 + x8 + x9 '
Hs.model <- ' visual =~ x1 + x2 + x3 textual =~ x4 + x5 + x6
Hs.model <- ' visual =~ x1 + x2 + x3 textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9 '
fit <- cfa(Hs.model, data = d)
'
Hs.model <- '
# latent variables
visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9
'
fit <- cfa(Hs.model, data = d)
Hs.model <- '
# latent variables
visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9
'
Hs.model
fit <- cfa(Hs.model, data = d)
fit
summary(fit)
summary(fit)
library(tidyverse)
library(here)
library(broom)
library(skimr)
library(readxl)
library(formattable)
options(scipen = 999)
# set seed for reproducibility - ensures results are the same each time script is run
set.seed(100)
# Formula:
MatchIt::matchit(premature_category ~ interview_age + demo_sex_v2 + ehi_y_ss_scoreb + average_puberty + scanner_num + combined_income_cat + highest_ed_category + race_ethnicity + twin_sib_status, data = dropped_premat_cov, method = "nearest", ratio = 3)
# MATCHING
# Groupings made using MatchIt package - 3:1 Full term:premature ratio.
# Matched to closest match on:
# age, sex, handedness,
# average puberty, scanner,
# combined income class, highest household education, race,
# and twin status
install.packages("MatchIt")
# set seed for reproducibility - ensures results are the same each time script is run
set.seed(100)
# LOAD AND CLEAN DATA
post_strat <- read_csv("../2.0_ABCD_Data_Explorer/2-0and2-0-1/ABCD ACS Post Stratification Weights.csv") %>%
filter(eventname == "baseline_year_1_arm_1") %>% select(src_subject_id, rel_relationship)
libary(mvnorm)
library(mvnorm)
mu <- c(10, 5)
sigma <- matrix(data = c(1,2, 5, 4))
sigma
sigma <- matrix(data = c(1,2, 5, 4), nrow = 2)
sigma
n <- 100
MASS::mvrnorm(n, mu, sigma)
mu <- c(0, 0)
n <- 100
# simulate standard normal
mu <- c(0, 0)
# Since the standard deviations of each distribution are 1
# the covariance matrix is equivalent to the correlation matrix.
sigma <- matrix(data = c(1, 0.15,
0.15, 1), nrow = 2)
sigma
MASS::mvrnorm(n, mu, sigma)
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble()
library(tidyverse)
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble()
d
MASS::mvrnorm(n, mu, sigma)
y = `V2')
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
y = `V2`)
d
cor(d)
n <- 100
# simulate standard normal
mu <- c(0, 0)
# Since the standard deviations of each distribution are 1
# the covariance matrix is equivalent to the correlation matrix.
sigma <- matrix(data = c(1, 0.15,
0.15, 1), nrow = 2)
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
y = `V2`)
cor(d)
set.seed(5)
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
y = `V2`)
cor(d)
corrr::correlate(d)
corrr::correlate(d) |>
shave()
library(corrr)
correlate(d) |>
shave()
correlate(d) |>
shave() |>
fashion()
correlate(d) |>
shave() |>
fashion() |>
rmarkdown::paged_table()
lm(y ~ x, data = d) |> summary()
mod <- lm(y ~ x, data = d)
mod |> predict()
y_pred <- mod |> predict()
d |>
cbind(y_pred)
d <- d |>
cbind(y_pred)
d <- d |>
# cbind(y_pred) |>
mutate(residuals = (y_pred - y)^2)
d
d |>
ggplot(aes(x = residuals)) |>
geom_histogram()
d |>
ggplot(aes(x = residuals)) +
geom_histogram()
d <- d |>
cbind(y_pred) |>
mutate(residuals = (y_pred - y))
d |>
ggplot(aes(x = residuals)) +
geom_histogram()
d |>
ggplot(aes(x = sqrt(residuals))) +
geom_histogram()
qqplot(d$y, d$y_pred)
d |>
ggplot(aes(x = x, y = residuals)) +
geom_histogram()
d |>
ggplot(aes(x = x, y = residuals)) +
geom_point()
d <- d |>
cbind(y_pred) |>
mutate(residuals = (y_pred - y)^2)
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
y = `V2`)
correlate(d) |>
shave() |>
fashion() |>
rmarkdown::paged_table()
mod <- lm(y ~ x, data = d)
y_pred <- mod |> predict()
d <- d |>
cbind(y_pred) |>
mutate(residuals = (y_pred - y)^2)
d |>
ggplot(aes(x = x, y = residuals)) +
geom_point()
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
y = `V2`)
correlate(d) |>
shave() |>
fashion() |>
rmarkdown::paged_table()
mod <- lm(y ~ x, data = d)
y_pred <- mod |> predict()
d <- d |>
cbind(y_pred) |>
mutate(residuals = (y_pred - y))
d |>
ggplot(aes(x = x, y = residuals)) +
geom_point()
d |>
ggplot(aes(x = y_pred, y = residuals)) +
geom_point()
d |>
ggplot(aes(x = y_pred, y = residuals)) +
geom_point()
d |>
ggplot(aes(x = y_pred, y = residuals)) +
geom_point() +
geom_hline(yintercept = 0) +
labs(title = "Fitted values against residuals")
?qqplot()
qqplot(d$y)
qqplot(d$y, d)
qqplot(d$y, d$x)
qqplot(d$y, d$y_pred)
qqplot(d$residuals, d$y_pred)
qqline(d$y)
qqline(d$y)
qplot(y, data = d)
qplot(sample = y, data = d)
qplot(sample = y, data = d) +
stat_qq()
qplot(sample = y, data = d) +
labs(x = "theoretical", y = "sample y")
qplot(sample = y, data = d) +
labs(x = "theoretical", y = "sample y", title = "QQ Plot")
qplot(sample = x, data = d) +
labs(x = "theoretical", y = "sample y", title = "QQ Plot")
qplot(sample = y, data = d) +
labs(x = "theoretical", y = "sample y", title = "QQ Plot")
d |>
ggplot(aes(x = y_pred, y = residuals)) +
geom_point()
mod
mod |>
summary()
set.seed(5)
n <- 100
# simulate standard normal
mu <- c(0, 0)
# Since the standard deviations of each distribution are 1
# the covariance matrix is equivalent to the correlation matrix.
sigma <- matrix(data = c(1, 0.15,
0.15, 1), nrow = 2)
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
y = `V2`)
correlate(d) |>
shave() |>
fashion() |>
rmarkdown::paged_table()
mod <- lm(y ~ x, data = d)
y_pred <- mod |> predict()
d <- d |>
cbind(y_pred) |>
mutate(residuals = (y_pred - y))
d |>
ggplot(aes(x = y_pred, y = residuals)) +
geom_point() +
geom_hline(yintercept = 0) +
labs(title = "Fitted values against residuals")
qplot(sample = y, data = d) +
labs(x = "theoretical", y = "sample y", title = "QQ Plot")
mod |>
summary()
d |>
ggplot(aes(x = x, y = y)) +
geom_point()
d |>
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm")
correlate(d) |>
shave() |>
fashion() |>
rmarkdown::paged_table()
n <- 10000
# simulate standard normal
mu <- c(0, 0)
# Since the standard deviations of each distribution are 1
# the covariance matrix is equivalent to the correlation matrix.
sigma <- matrix(data = c(1, 0.15,
0.15, 1), nrow = 2)
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
y = `V2`)
correlate(d) |>
shave() |>
fashion() |>
rmarkdown::paged_table()
lm(y ~ x, data = d)
<- lm(y ~ 0 +x, data = d) |>
lm(y ~ 0 + x, data = d) |>
```
lm(y ~ x, data = d) |>
```
lm(y ~ x, data = d) |>
summary()
n <- 100000
# simulate standard normal
mu <- c(0, 0)
n <- 100000
# simulate standard normal
mu <- c(0, 0)
# Since the standard deviations of each distribution are 1
# the covariance matrix is equivalent to the correlation matrix.
sigma <- matrix(data = c(1, 0.15,
0.15, 1), nrow = 2)
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
y = `V2`)
correlate(d) |>
shave() |>
fashion() |>
rmarkdown::paged_table()
lm(y ~ x, data = d) |>
summary()
mod |>
summary() |>
tidy()
mod |>
tidy()
mod |>
broom:;tidy()
mod |>
broom::tidy()
mod |>
broom::tidy() |>
round(3)
mod |>
broom::tidy() |>
mutate(across(where(is.numeric), ~round(2)))
mod |>
broom::tidy() |>
mutate(across(where(is.numeric), ~round(3)))
mod |>
broom::tidy() |>
mutate(across(where(is.numeric), ~round(.x, 3)))
lm(y ~ x, data = d) |>
summary() >
broom::tidy() |>
mutate(across(where(is.numeric), ~round(.x, 3)))
lm(y ~ x, data = d) |>
summary() >
broom::tidy() |>
mutate(across(where(is.numeric), ~round(.x, 3)))
lm(y ~ x, data = d) |>
broom::tidy() |>
mutate(across(where(is.numeric), ~round(.x, 3)))
correlate(d) |>
shave() |>
rmarkdown::paged_table()
n <- 100
# simulate standard normal
mu <- c(0, 0)
# Since the standard deviations of each distribution are 1
# the covariance matrix is equivalent to the correlation matrix.
sigma <- matrix(data = c(1, 0.15,
0.15, 1), nrow = 2)
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
y = `V2`)
correlate(d) |>
shave() |>
rmarkdown::paged_table()
set.seed(5)
n <- 100
# simulate standard normal
mu <- c(0, 0)
# Since the standard deviations of each distribution are 1
# the covariance matrix is equivalent to the correlation matrix.
sigma <- matrix(data = c(1, 0.15,
0.15, 1), nrow = 2)
d <- MASS::mvrnorm(n, mu, sigma) |>
as_tibble() |>
rename(x = `V1`,
y = `V2`)
correlate(d) |>
shave() |>
rmarkdown::paged_table()
